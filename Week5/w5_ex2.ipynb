{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "# another way of ignoring warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path().cwd()\n",
    "data_file = path.parent / \"Data\" / \"ClevelandHeartData.csv\"\n",
    "\n",
    "T = pd.read_csv(data_file, sep=';')\n",
    "X = T.loc[:, T.columns != 'Diagnosis']\n",
    "y = np.array(T.loc[:, T.columns == 'Diagnosis'])\n",
    "\n",
    "# Some of the data is written in a European format, that doesn't work in python\n",
    "X['Oldpeak'] = pd.Series(X['Oldpeak']).str.replace(',', '.')\n",
    "# Decision trees in python don't handle NaN values in the same way as in matlab\n",
    "# This model does not support missing values\n",
    "# we replace every empty value with the column's mode since we have categorical \n",
    "for column in X.columns:\n",
    "    X[column].fillna(X[column].mode()[0], inplace=True)\n",
    "\n",
    "\n",
    "Xlabel = np.array(T.columns[:-1])\n",
    "Nobs = len(T)\n",
    "Nfeature = len(Xlabel)\n",
    "print(f'Number of observations: {Nobs}.')\n",
    "print(f'Number of features: {Nfeature}.')\n",
    "print(f'Labels of features: {Xlabel}')\n",
    "print(T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Matlab and R have functions for building, pruning, evaluating and viewing classification and regression trees. We are going touse them to diagnose heart problems based on a set of 13 clinical variables from 303 patients and healthy controls. The data is in the file ClevelandHeartData.csv. The first 13 columns are di\u000b",
    "erent features and the 14th column is an indicator for heart problem/healthy. You can read more about the data in ClevelandHeartDataDescription.txt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> a) Read the help files for the tree methods in your preferred language to familiarize yourself with the possibilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read about options in the DecisionTreeClassifier at http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> b) Build a large tree with the minimum number of observations (minLeaf ) in at leaf\n",
    "set to 1 and view the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Build and view a large tree\n",
    "dtree=\n",
    "\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(nrows = 1,ncols = 1,figsize = (10,10), dpi=300)\n",
    "tree.plot_tree(dtree,\n",
    "               feature_names = Xlabel,\n",
    "               class_names = ['No Diagnose','Diagnose'],\n",
    "               filled = True);\n",
    "\n",
    "#A little description of the information at each plotted node\n",
    "#1. row: The condition\n",
    "#2. row: The impurity score of the node\n",
    "#3. row: The number of observations at this node\n",
    "#4. row: The number of samples for each class at this node\n",
    "#5. row: The class by majority voting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> c) Choose optimal tree size by tuning the parameter MinLeaf value using cross\n",
    "validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use cross validation to tune the hyper parameter for nim_sample_leaf\n",
    "# use sklearns GridSearchCV\n",
    "dtree = \n",
    "\n",
    "cv_grid = \n",
    "\n",
    "# Fit the grid search model\n",
    "\n",
    "\n",
    "#plot the results\n",
    "plt.plot(range(1,50),cv_grid.cv_results_['mean_test_score'])\n",
    "plt.xlabel('Min_samples_leaf')\n",
    "plt.ylabel('Testaccuracy')\n",
    "print(f'best estimator: {cv_grid.best_estimator_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One standard error rule\n",
    "meanError = list(cv_grid.cv_results_['mean_test_score'])\n",
    "stdError = cv_grid.cv_results_['std_test_score']\n",
    "# this is the index of the smallest error\n",
    "\n",
    "# the model picks model with highest accuracy and because of that we use max\n",
    "maxAcc = meanError.index(max(meanError))\n",
    " # model does accuracy and not error so we flip shit!\n",
    "J = np.where(meanError[maxAcc] - stdError[maxAcc] < meanError)[0]\n",
    "\n",
    "if (len(J) > 0):\n",
    "    j = int(J[-1::])\n",
    "else:\n",
    "    j = minError\n",
    "\n",
    "min_sample_leaf_opt = j+1\n",
    "print (f'One standard error rule gives min_samples_leaf: {min_sample_leaf_opt}') # +1 because zero indexed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> d) View the optimal tree and try to interpret it such that it makes sense for a doctor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Build a tree based on best nim_sample_leaf\n",
    "dtree=\n",
    "\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(nrows = 1,ncols = 1,figsize = (10,10), dpi=300)\n",
    "tree.plot_tree(dtree,\n",
    "               feature_names = Xlabel,\n",
    "               class_names = ['No Diagnose','Diagnose'],\n",
    "               filled = True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If you have scikit-learn 0.22 <= then you can also find the tree size through cost complexity pruning of the best estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we prune the tree instead of using the one std error because the tree becomes too small\n",
    "# use cross validation to minimize cost complexity pruning\n",
    "\n",
    "dtree =\n",
    "\n",
    "cv_grid = \n",
    "\n",
    "# Fit the grid search model\n",
    "\n",
    "\n",
    "print(f'best estimator: {cv_grid.best_estimator_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a tree based on best pruning params\n",
    "dtree=\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(nrows = 1,ncols = 1,figsize = (10,10), dpi=300)\n",
    "tree.plot_tree(dtree,\n",
    "               feature_names = Xlabel,\n",
    "               class_names = ['No Diagnose','Diagnose'],\n",
    "               filled = True);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
